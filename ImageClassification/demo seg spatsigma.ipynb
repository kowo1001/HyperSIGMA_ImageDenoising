{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import SpatViT_seg\n",
    "import torch\n",
    "from torch  import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report,cohen_kappa_score\n",
    "from model import split_data,utils,create_graph\n",
    "#from sklearn import metrics, preprocessing\n",
    "from mmengine.optim import build_optim_wrapper\n",
    "from mmcv_custom import custom_layer_decay_optimizer_constructor,layer_decay_optimizer_constructor_vit\n",
    "import torch.utils.data as Data\n",
    "import scipy.io as sio\n",
    "import spectral as spy\n",
    "from collections import Counter\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataReader():\n",
    "    def __init__(self):\n",
    "        self.data_cube = None\n",
    "        self.g_truth = None\n",
    "\n",
    "    @property\n",
    "    def cube(self):\n",
    "        \"\"\"\n",
    "        origin data\n",
    "        \"\"\"\n",
    "        return self.data_cube\n",
    "\n",
    "    @property\n",
    "    def truth(self):\n",
    "        return self.g_truth\n",
    "\n",
    "    @property\n",
    "    def normal_cube(self):\n",
    "        \"\"\"\n",
    "        normalization data: range(0, 1)\n",
    "        \"\"\"\n",
    "        return (self.data_cube - np.min(self.data_cube)) / (np.max(self.data_cube) - np.min(self.data_cube))\n",
    "class IndianRaw(DataReader):\n",
    "    def __init__(self):\n",
    "        super(IndianRaw, self).__init__()\n",
    "        raw_data_package = sio.loadmat(r\"data/Indian_pines_corrected.mat\")\n",
    "        self.data_cube = raw_data_package[\"data\"].astype(np.float32)\n",
    "        truth = sio.loadmat(r\"data/Indian_pines_gt.mat\")\n",
    "        self.g_truth = truth[\"groundT\"].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    data = IndianRaw().cube\n",
    "    data_gt = IndianRaw().truth\n",
    "    return data, data_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size= 8\n",
    "img_size = 128\n",
    "pca_components = 30\n",
    "split_type = ['number', 'ratio'][0]\n",
    "train_num = 10\n",
    "val_num =0\n",
    "train_ratio = 0.999  \n",
    "val_ratio = 0.001 \n",
    "\n",
    "max_epoch = 300\n",
    "batch_size = 64 \n",
    "dataset_name = 'HH'\n",
    "\n",
    "path_weight = r\"weights//\"\n",
    "path_result = r\"result//\"\n",
    "data, data_gt = load_data()\n",
    "height_orgin, width_orgin, bands = data.shape\n",
    "class_num = np.max(data_gt)\n",
    "class_num = class_num.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, pca = split_data.apply_PCA(data, num_components=pca_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_reshape = np.reshape(data_gt, [-1])\n",
    "train_index, val_index, test_index = split_data.split_data(gt_reshape, \n",
    "            class_num, train_ratio, train_ratio, train_num, val_num, split_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index=train_index.astype(int)\n",
    "val_index=val_index.astype(int)\n",
    "test_index=test_index.astype(int)\n",
    "gt_reshape = np.reshape(data_gt, [-1])\n",
    "class_num = np.max(gt_reshape)\n",
    "class_num = class_num.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples_gt, test_samples_gt, val_samples_gt = create_graph.get_label(gt_reshape,\n",
    "                                                train_index, val_index, test_index)\n",
    "\n",
    "train_label_mask, test_label_mask, val_label_mask = create_graph.get_label_mask(train_samples_gt, \n",
    "                                        test_samples_gt, val_samples_gt, data_gt, class_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gt = np.reshape(train_samples_gt,[height_orgin,width_orgin])\n",
    "test_gt = np.reshape(test_samples_gt,[height_orgin,width_orgin])\n",
    "val_gt = np.reshape(val_samples_gt,[height_orgin,width_orgin])\n",
    "\n",
    "\n",
    "train_gt_onehot = create_graph.label_to_one_hot(train_gt, class_num)\n",
    "test_gt_onehot = create_graph.label_to_one_hot(test_gt, class_num)\n",
    "val_gt_onehot = create_graph.label_to_one_hot(val_gt, class_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples_gt=torch.from_numpy(train_samples_gt.astype(np.float32)).to(device)\n",
    "test_samples_gt=torch.from_numpy(test_samples_gt.astype(np.float32)).to(device)\n",
    "val_samples_gt=torch.from_numpy(val_samples_gt.astype(np.float32)).to(device)\n",
    "train_gt_onehot = torch.from_numpy(train_gt_onehot.astype(np.float32)).to(device)\n",
    "test_gt_onehot = torch.from_numpy(test_gt_onehot.astype(np.float32)).to(device)\n",
    "val_gt_onehot = torch.from_numpy(val_gt_onehot.astype(np.float32)).to(device)\n",
    "\n",
    "train_label_mask = torch.from_numpy(train_label_mask.astype(np.float32)).to(device)\n",
    "test_label_mask = torch.from_numpy(test_label_mask.astype(np.float32)).to(device)\n",
    "val_label_mask = torch.from_numpy(val_label_mask.astype(np.float32)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train, num_H, num_W,data_gt,data =  utils.Get_train_and_test_data(img_size, data,data_gt)\n",
    "height, width, bands = data.shape \n",
    "img_train = torch.from_numpy(img_train.transpose(0,3,1,2)).type(torch.FloatTensor) \n",
    "data_train = Data.TensorDataset(img_train)\n",
    "train_loader = Data.DataLoader(data_train, batch_size=num_H,shuffle=False)\n",
    "val_loader = Data.DataLoader(data_train, batch_size=num_H,shuffle=False)\n",
    "test_loader = Data.DataLoader(data_train, batch_size=num_H,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples_gt[train_index] = train_samples_gt[train_index] -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = torch.zeros([height_orgin * width_orgin]).to(device).float()\n",
    "model = SpatViT_seg.SpatViT (img_size=img_size,\n",
    "            num_classes = class_num,\n",
    "            in_chans=pca_components,\n",
    "            patch_size=patch_size,\n",
    "            drop_path_rate=0.1,\n",
    "            out_indices=[3, 5, 7, 11],\n",
    "            embed_dim=768,\n",
    "            depth=12,\n",
    "            num_heads=12,\n",
    "            mlp_ratio=4,\n",
    "            qkv_bias=True,\n",
    "            qk_scale=None,\n",
    "            drop_rate=0.,\n",
    "            attn_drop_rate=0.,\n",
    "            use_checkpoint=True,\n",
    "            use_abs_pos_emb=False,\n",
    "            interval = 3,\n",
    "            n_points=8).to(device)\n",
    "\n",
    "per_net = torch.load((r\"spat-base.pth\"), map_location=torch.device('cpu'))\n",
    "model_params =model.state_dict()\n",
    "for k in list(per_net['model'].keys()):\n",
    "    if 'patch_embed.proj' in k:\n",
    "        del per_net['model'][k]\n",
    "    if 'pos_embed' in k:\n",
    "        del per_net['model'][k]\n",
    "same_parsms = {k: v for k, v in per_net['model'].items() if k in model_params.keys()}\n",
    "model_params.update(same_parsms)\n",
    "model.load_state_dict(model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optim_wrapper = dict(\n",
    "    optimizer=dict(\n",
    "    type='AdamW', lr=6e-5, betas=(0.9, 0.999), weight_decay=0.05),\n",
    "    constructor='LayerDecayOptimizerConstructor_ViT', \n",
    "    paramwise_cfg=dict(\n",
    "        num_layers=12, \n",
    "        layer_decay_rate=0.9,\n",
    "        )\n",
    "        )\n",
    "optimizer = build_optim_wrapper(model, optim_wrapper)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer.optimizer, max_epoch, eta_min=0, last_epoch=-1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model.to(device)\n",
    "count = 0\n",
    "best_loss = 99999\n",
    "train_losses = []\n",
    "val_losses = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(max_epoch+ 1):\n",
    "    pred = torch.zeros([num_W, num_H, class_num, img_size, img_size])\n",
    "    optimizer.zero_grad() \n",
    "    for batch_idx, (batch_data) in enumerate(train_loader):\n",
    "        for i in range(num_H):\n",
    "            netinput = batch_data[0][i]\n",
    "            netinput = torch.unsqueeze(netinput, 0).to(device)\n",
    "            batch_pred = model(netinput)\n",
    "            #batch_pred = batch_pred.detach()\n",
    "            batch_pred = batch_pred.reshape(img_size,img_size,-1)\n",
    "            batch_pred =batch_pred. permute(([2, 0, 1]), 0)\n",
    "            pred[batch_idx,i] = batch_pred\n",
    "    pred = torch.reshape(pred, [num_H, num_W, class_num, img_size, img_size])\n",
    "    pred = torch.permute(pred, [2, 0, 3, 1, 4])  # [2,num_H, img_size,num_W, img_size]]\n",
    "    pred = torch.reshape(pred, [class_num, num_H * img_size* num_W * img_size])\n",
    "    pred = torch.permute(pred, [1, 0])     \n",
    "    y =pred.to(device)\n",
    "    train_index =train_index.reshape(-1,)\n",
    "    y_orgin =  utils.image_reshape(y,height,width,height_orgin,width_orgin,class_num)\n",
    "    loss = criterion(y_orgin[train_index], train_samples_gt[train_index].long())\n",
    "    loss.backward(retain_graph=False)\n",
    "    optimizer.step()\n",
    "    if epoch%10==0:\n",
    "        trainOA = utils.evaluate_performance(y_orgin, train_samples_gt, train_gt_onehot, zeros)\n",
    "        print(\"{}\\ttrain loss={:.4f}\\t train OA={:.4f} \".format(str(epoch + 1), loss, trainOA))\n",
    "        if loss < best_loss :\n",
    "            best_loss = loss\n",
    "            print('save model')\n",
    "            torch.save(model.state_dict(), path_weight + r\"model.pt\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "with torch.no_grad():\n",
    "    model.load_state_dict(torch.load(path_weight + r\"model.pt\"))\n",
    "    model.eval()\n",
    "    pred = torch.zeros([num_W, num_H, class_num, img_size, img_size])\n",
    "    for batch_idx, (batch_data) in enumerate(test_loader):\n",
    "        for w in range(num_H):\n",
    "            netinput = batch_data[0][w]\n",
    "            netinput = torch.unsqueeze(netinput, 0).to(device)\n",
    "            batch_pred = model(netinput)\n",
    "            #batch_pred = batch_pred.detach()\n",
    "            batch_pred = batch_pred.reshape(img_size,img_size,-1)\n",
    "            batch_pred =batch_pred. permute(([2, 0, 1]), 0)\n",
    "            pred[batch_idx,w] = batch_pred\n",
    "    pred = torch.reshape(pred, [num_H, num_W, class_num, img_size, img_size])\n",
    "    pred = torch.permute(pred, [2, 0, 3, 1, 4])  # [2,num_H, img_size,num_W, img_size]]\n",
    "    pred = torch.reshape(pred, [class_num, num_H * img_size* num_W * img_size])\n",
    "    pred = torch.permute(pred, [1, 0])     \n",
    "    y =pred.to(device)\n",
    "    y_orgin =  utils.image_reshape(y,height,width,height_orgin,width_orgin,class_num)\n",
    "    overall_acc,OA_hi1,average_acc,kappa,each_acc=utils.evaluate_performance_all(y_orgin, test_samples_gt, test_gt_onehot,  height_orgin, width_orgin, class_num, test_gt,device, require_AA_KPP=True, printFlag=False)\n",
    "    print(\"test OA={:.4f}\".format(overall_acc))\n",
    "    print('kappa=',kappa)\n",
    "    print('each_acc=',each_acc)\n",
    "    print('average_acc=',average_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
